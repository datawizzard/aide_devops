{
  "generated_at": "2025-09-09T15:40:25.067671+00:00",
  "user_requirement": "One positive rate per currency per day; no gaps for major currencies",
  "system_prompt": "# SYSTEM\n\nYou are a senior data quality engineer. Generate SQL rules that detect VIOLATIONS for the described quality requirement (USER REQUEST). Rules must handle:\n\n1) Multi-table checks (joins across fact/dim, cross-database in Unity Catalog)\n2) Complex relationships (multi-hop RI)\n3) Hierarchies/trees (orphans, cycles, inconsistent parent-child attrs)\n4) Cross-links between hierarchies (consistency across classification systems)\n\n## Output contract\n\nRespond ONLY with a JSON array of rule objects. No code fences or prose outside the JSON.\n\nEach rule object MUST include:\n\n- \"name\": short, human-readable identifier\n- \"description\": clear explanation; document conservative assumptions if anything is ambiguous/missing (e.g., missing DDL for a referenced table)\n- \"severity\": one of [\"LOW\",\"MEDIUM\",\"HIGH\",\"CRITICAL\"]\n- \"sql\": a Databricks SQL statement that returns ONLY violating rows (0 rows = pass)\n\n## SQL authoring rules (Databricks / Unity Catalog)\n\n- Use ONLY identifiers (tables, columns) that appear in CREATE TABLE/VIEW statements of the RELEVANT DDLs section.\n- Ignore identifiers from the EXAMPLES section.\n- Use fully qualified UC names and quote identifiers with backticks (catalog, schema, tables, columns) for all identifiers except aliases.\n- Return ONLY: identifying keys, minimal helpful context columns, and a final column named violation_reason (VARCHAR) explaining why each row failed.\n- Do NOT use SELECT *; list columns explicitly.\n- Be side-effect free (no DDL/DML).\n- Avoid non-determinism: no ORDER BY, LIMIT, RAND, or UDFs; use current_date() only if the rule requires time.\n- Prefer NOT EXISTS (anti-joins) for referential checks to avoid duplicates; use LEFT JOIN ... IS NULL only when strictly needed.\n- Normalize text comparisons with lower(trim(col)).\n- Interpret \"active\" flags with:\n  case when lower(trim(col)) in ('y','yes','true','1','active') then 'active'\n       when lower(trim(col)) in ('n','no','false','0','inactive') then 'inactive'\n       else 'unknown' end\n- Parse string dates via try_to_timestamp(col) or try_to_date(col); compare to current_date() for date rules.\n- For duplicates, use row_number() over (partition by <candidate key> order by <stable expression>) > 1.\n- For hierarchical cycle checks, use a recursive CTE with a reasonable depth guard (e.g., 100) and return the discovered path in violation_reason.\n- If profiling context is provided, infer candidate keys conservatively (e.g., approx_distinct ~= row_count implies uniqueness). If uncertain, say so in description and still provide a safe rule.\n\n## DATA vs METADATA guardrails (CRITICAL)\n\n- Row-level verification only: Never decide pass/fail from metadata/DDL flags (e.g., is_nullable, data_type). Always scan actual data rows in domain tables (e.g., WHERE `col` IS NULL).\n- Do NOT query metadata/system catalogs in FROM/JOIN (e.g., INFORMATION_SCHEMA.*, sys.*, pg_catalog.*, DESCRIBE/SHOW outputs) or schema-introspection/profiler views (tables with columns like table_name, column_name, data_type, is_nullable), unless the USER REQUEST explicitly asks to validate metadata.\n- Each rule MUST include at least one DOMAIN DATA TABLE (from RELEVANT DDLs) in the top-level FROM clause.\n- You may use metadata conceptually to infer keys/joins but it must not appear in the SQL or determine pass/fail.\n\n## Use of context\n\n- Use ONLY identifiers provided by RELEVANT DDLs.\n- If a referenced table is absent from RELEVANT DDLs, state the assumption explicitly in \"description\" and produce best-effort rules using tables that DO appear in RELEVANT DDLs. Do NOT fall back to metadata tables.\n- Favor keys/constraints suggested by profiling (uniqueness, nullability), but implement them as data scans.\n\n## Behavioral examples (for steering only; do NOT reuse identifiers)\n\nNOT OK (metadata-based null check):\n\n- Reads `is_nullable` from a schema/metadata table to claim null violations.\n\nOK (data-based null check):\n\n- SELECT `employee_id`, `skill_id`, 'proficiency is NULL' AS violation_reason\n  FROM `cat`.`sch`.`employee_skill`\n  WHERE `proficiency` IS NULL\n\nWhen generating your answer, respond ONLY with WELL-FORMED JSON containing the array of rules. NEVER return partial or invalid JSON. No code fences, markdown, or any text outside the JSON.",
  "rules": [
    {
      "name": "Positive exchange rate per currency per day",
      "sql": "SELECT fcr.`CurrencyKey`,\n       fcr.`DateKey`,\n       fcr.`Date`,\n       'No positive exchange rate recorded for this currency on this day' AS `violation_reason`\nFROM `aigdqr-ragstoriches`.`adv_works_dw`.`factcurrencyrate` fcr\nJOIN `aigdqr-ragstoriches`.`adv_works_dw`.`dimcurrency` dc ON fcr.`CurrencyKey` = dc.`CurrencyKey`\nWHERE NOT EXISTS\n    (SELECT 1\n     FROM `aigdqr-ragstoriches`.`adv_works_dw`.`factcurrencyrate` fcr_inner\n     WHERE fcr_inner.`CurrencyKey` = fcr.`CurrencyKey`\n       AND fcr_inner.`DateKey` = fcr.`DateKey`\n       AND fcr_inner.`AverageRate` > 0)",
      "severity": "CRITICAL",
      "description": "Ensure that for each major currency, there is at least one positive exchange rate recorded per day in the factcurrencyrate table. Assumes major currencies are identified by their presence in dimcurrency."
    },
    {
      "name": "No gaps in exchange rate records for major currencies",
      "sql": "WITH date_range AS\n  (SELECT DISTINCT `DateKey`\n   FROM `aigdqr-ragstoriches`.`adv_works_dw`.`factcurrencyrate`),\n     missing_dates AS\n  (SELECT dc.`CurrencyKey`,\n          dr.`DateKey`\n   FROM `aigdqr-ragstoriches`.`adv_works_dw`.`dimcurrency` dc\n   CROSS JOIN date_range dr\n   WHERE NOT EXISTS\n       (SELECT 1\n        FROM `aigdqr-ragstoriches`.`adv_works_dw`.`factcurrencyrate` fcr\n        WHERE fcr.`CurrencyKey` = dc.`CurrencyKey`\n          AND fcr.`DateKey` = dr.`DateKey`))\nSELECT md.`CurrencyKey`,\n       md.`DateKey`,\n       'Missing exchange rate record for this currency on this day' AS `violation_reason`\nFROM missing_dates md",
      "severity": "HIGH",
      "description": "Ensure there are no gaps in exchange rate records for major currencies in the factcurrencyrate table. Assumes major currencies are identified by their presence in dimcurrency and gaps are defined as missing DateKey entries for a CurrencyKey."
    }
  ]
}